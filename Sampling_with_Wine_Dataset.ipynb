{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sampling with Wine Dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpwxDEFvnlHJVTF6bJSMUV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragatischdv/SamplingNF/blob/main/Sampling_with_Wine_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nflows"
      ],
      "metadata": {
        "id": "7uvCp3kaQ2YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D4JOI0r-QAuA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from sklearn.decomposition import PCA\n",
        " \n",
        "from nflows.flows.base import Flow\n",
        "from nflows.distributions.normal import StandardNormal\n",
        "from nflows.transforms.base import CompositeTransform\n",
        "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
        "from nflows.transforms.coupling import AffineCouplingTransform\n",
        "from nflows.transforms.linear import NaiveLinear\n",
        "from nflows.transforms.permutations import ReversePermutation\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.read_csv(\"/content/winequality-white.csv\")\n",
        "input_data = data1.drop(\"quality\", axis=1)\n",
        "output_data = np.array(data1[\"quality\"])"
      ],
      "metadata": {
        "id": "jcALIwsLQchq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_CLASS_INT = 9\n",
        "MIN_CLASS_INT = 3\n",
        "N_SAMPLES = 273"
      ],
      "metadata": {
        "id": "45_o-vIePp47"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 1)\n",
        "input_data = pca.fit_transform(input_data)"
      ],
      "metadata": {
        "id": "XhVtasJ_RZWh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = []\n",
        "for i in range(len(output_data)):\n",
        "  final_data.append([input_data[i][0], output_data[i]])\n",
        "\n",
        "final_data = np.array(final_data)"
      ],
      "metadata": {
        "id": "zwGpxsluR9Oi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 7\n",
        "base_dist = StandardNormal(shape=[2])\n",
        "num_iter = 10000"
      ],
      "metadata": {
        "id": "0uLuvTwZJ34f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masked Autoregrssive Flow"
      ],
      "metadata": {
        "id": "rL2-aUeDKBzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = []\n",
        "for _ in range(num_layers):\n",
        "     transforms.append(MaskedAffineAutoregressiveTransform(features=2, \n",
        "                                                            hidden_features=4))\n",
        "\n",
        "transform = CompositeTransform(transforms)\n",
        "\n",
        "flow = Flow(transform, base_dist)\n",
        "optimizer = optim.Adam(flow.parameters())"
      ],
      "metadata": {
        "id": "Jmhisli0Q_Lb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_iter = 10000\n",
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer.zero_grad()\n",
        "    loss = -flow.log_prob(inputs=x).mean()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "ekMIO4xuRt3H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoregressive Flow with Coupling layer"
      ],
      "metadata": {
        "id": "kyKWGhhxLx5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = [1,1]\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channel, out_channels):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_channel, in_channel),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_channel, in_channel),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_channel, out_channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, inp, context=None):\n",
        "        return self.net(inp)\n",
        "\n",
        "def getNet(in_channel, out_channels):\n",
        "        return Net(in_channel, out_channels)\n",
        "transforms_cl = []\n",
        "for _ in range(num_layers):\n",
        "     transforms_cl.append(AffineCouplingTransform(mask, getNet))\n",
        "\n",
        "transform_cl = CompositeTransform(transforms_cl)\n",
        "\n",
        "flow_cl = Flow(transform_cl, base_dist)\n",
        "optimizer_cl = optim.Adam(flow_cl.parameters())"
      ],
      "metadata": {
        "id": "Vud6whJGJ0fj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer_cl.zero_grad()\n",
        "    loss_cl = -flow_cl.log_prob(inputs=x).mean()\n",
        "    loss_cl.backward()\n",
        "    optimizer_cl.step()"
      ],
      "metadata": {
        "id": "x8r7b9q8Kh2p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Flow"
      ],
      "metadata": {
        "id": "z-aUvPS9NXyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nflows.transforms.permutations import ReversePermutation\n",
        "transforms_l = []\n",
        "\n",
        "for _ in range(num_layers):\n",
        "     transforms_l.append(ReversePermutation(features=2))\n",
        "     transforms_l.append(NaiveLinear(features=2))\n",
        "\n",
        "transform_l = CompositeTransform(transforms_l)\n",
        "\n",
        "flow_l = Flow(transform_l, base_dist)\n",
        "optimizer_l = optim.Adam(flow_l.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMdwGIRNL54M",
        "outputId": "17051112-c543-4132-bec2-2ced7f7c8858"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nflows/utils/torchutils.py:73: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
            "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
            "Q, R = torch.qr(A, some)\n",
            "should be replaced with\n",
            "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1980.)\n",
            "  q, _ = torch.qr(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer_l.zero_grad()\n",
        "    loss_l = -flow_l.log_prob(inputs=x).mean()\n",
        "    loss_l.backward()\n",
        "    optimizer_l.step()"
      ],
      "metadata": {
        "id": "TlAaJDr9MOOu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def guassianNB_accuracy(flow):\n",
        "  max_accuracy = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = GaussianNB()\n",
        "    model_with_sampled_data = GaussianNB()\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy < accuracy:\n",
        "      max_accuracy = accuracy\n",
        "\n",
        "  print(max_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "GkQ4uLRYP9N2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_accuracy(flow):  \n",
        "  max_accuracy_lr = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(273):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = LogisticRegression(random_state = 0)\n",
        "    model_with_sampled_data = LogisticRegression(random_state = 0)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_lr < accuracy:\n",
        "      max_accuracy_lr = accuracy\n",
        "\n",
        "  print(max_accuracy_lr)"
      ],
      "metadata": {
        "id": "hSMSObf_RNEO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_accuracy(flow):\n",
        "  max_accuracy_knn = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(273):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = KNeighborsClassifier(n_neighbors=7)\n",
        "    model_with_sampled_data = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_knn < accuracy:\n",
        "      max_accuracy_knn = accuracy\n",
        "\n",
        "  print(max_accuracy_knn)"
      ],
      "metadata": {
        "id": "da3A30LWSym2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest_accuracy(flow):  \n",
        "  max_accuracy_rf = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(273):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = RandomForestClassifier(n_estimators = 100)\n",
        "    model_with_sampled_data = RandomForestClassifier(n_estimators = 100)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_rf < accuracy:\n",
        "      max_accuracy_rf = accuracy\n",
        "\n",
        "  print(max_accuracy_rf) #0.3"
      ],
      "metadata": {
        "id": "1svzjhfUTLz9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guassianNB_accuracy(flow)\n",
        "guassianNB_accuracy(flow_cl)\n",
        "guassianNB_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnDlCAQrMeEu",
        "outputId": "a478ab56-104e-4f44-dde0-e9616c263c79"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.46153846153846156\n",
            "0.4652014652014652\n",
            "0.43956043956043955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_accuracy(flow)\n",
        "logistic_regression_accuracy(flow_cl)\n",
        "logistic_regression_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqQ51OyLMkXg",
        "outputId": "6dfbd919-af4c-4345-98db-9c5a96c3a18d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4945054945054945\n",
            "0.46153846153846156\n",
            "0.4908424908424908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_accuracy(flow)\n",
        "knn_accuracy(flow_cl)\n",
        "knn_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZRO5ZOjMuUp",
        "outputId": "32e97b5a-c9a0-4f53-f273-c642beea92ba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.358974358974359\n",
            "0.31135531135531136\n",
            "0.336996336996337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_accuracy(flow)\n",
        "random_forest_accuracy(flow_cl)\n",
        "random_forest_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsHz-qQ9Mzmr",
        "outputId": "ce3f54fa-0008-435b-c0c7-21e0a5200d72"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27472527472527475\n",
            "0.23443223443223443\n",
            "0.2271062271062271\n"
          ]
        }
      ]
    }
  ]
}