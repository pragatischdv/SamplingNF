{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sampling with Iris Flower Dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmuEoJPn6MeUUOdbd4EE5Z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nflows"
      ],
      "metadata": {
        "id": "7uvCp3kaQ2YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D4JOI0r-QAuA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from sklearn.decomposition import PCA\n",
        " \n",
        "from nflows.flows.base import Flow\n",
        "from nflows.distributions.normal import StandardNormal\n",
        "from nflows.transforms.base import CompositeTransform\n",
        "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
        "from nflows.transforms.coupling import AffineCouplingTransform\n",
        "from nflows.transforms.linear import NaiveLinear\n",
        "from nflows.transforms.permutations import ReversePermutation\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/iris_flower.csv\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DxrcgoWYDaf",
        "outputId": "e6c6d692-2a8e-4ac3-e9b4-2eadbcd3a378"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width  type\n",
            "0           5.1          3.5           1.4          0.2     1\n",
            "1           4.9          3.0           1.4          0.2     1\n",
            "2           4.7          3.2           1.3          0.2     1\n",
            "3           4.6          3.1           1.5          0.2     1\n",
            "4           5.0          3.6           1.4          0.2     1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = data.drop(\"type\", axis=1)\n",
        "output_data = np.array(data[\"type\"])"
      ],
      "metadata": {
        "id": "jcALIwsLQchq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_CLASS_INT = 3\n",
        "MIN_CLASS_INT = 1\n",
        "N_SAMPLES = len(data)"
      ],
      "metadata": {
        "id": "45_o-vIePp47"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 1)\n",
        "input_data = pca.fit_transform(input_data)"
      ],
      "metadata": {
        "id": "XhVtasJ_RZWh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = []\n",
        "for i in range(len(output_data)):\n",
        "  final_data.append([input_data[i][0], output_data[i]])\n",
        "\n",
        "final_data = np.array(final_data)"
      ],
      "metadata": {
        "id": "zwGpxsluR9Oi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 7\n",
        "base_dist = StandardNormal(shape=[2])\n",
        "num_iter = 10000"
      ],
      "metadata": {
        "id": "0uLuvTwZJ34f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masked Autoregrssive Flow"
      ],
      "metadata": {
        "id": "rL2-aUeDKBzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = []\n",
        "for _ in range(num_layers):\n",
        "     transforms.append(MaskedAffineAutoregressiveTransform(features=2, \n",
        "                                                            hidden_features=4))\n",
        "\n",
        "transform = CompositeTransform(transforms)\n",
        "\n",
        "flow = Flow(transform, base_dist)\n",
        "optimizer = optim.Adam(flow.parameters())"
      ],
      "metadata": {
        "id": "Jmhisli0Q_Lb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer.zero_grad()\n",
        "    loss = -flow.log_prob(inputs=x).mean()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "ekMIO4xuRt3H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoregressive Flow with Coupling layer"
      ],
      "metadata": {
        "id": "kyKWGhhxLx5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = [1,1]\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channel, out_channels):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_channel, in_channel),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_channel, in_channel),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_channel, out_channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, inp, context=None):\n",
        "        return self.net(inp)\n",
        "\n",
        "def getNet(in_channel, out_channels):\n",
        "        return Net(in_channel, out_channels)\n",
        "transforms_cl = []\n",
        "for _ in range(num_layers):\n",
        "     transforms_cl.append(AffineCouplingTransform(mask, getNet))\n",
        "\n",
        "transform_cl = CompositeTransform(transforms_cl)\n",
        "\n",
        "flow_cl = Flow(transform_cl, base_dist)\n",
        "optimizer_cl = optim.Adam(flow_cl.parameters())"
      ],
      "metadata": {
        "id": "Vud6whJGJ0fj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer_cl.zero_grad()\n",
        "    loss_cl = -flow_cl.log_prob(inputs=x).mean()\n",
        "    loss_cl.backward()\n",
        "    optimizer_cl.step()"
      ],
      "metadata": {
        "id": "x8r7b9q8Kh2p"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Flow"
      ],
      "metadata": {
        "id": "z-aUvPS9NXyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_l = []\n",
        "\n",
        "for _ in range(num_layers):\n",
        "     transforms_l.append(ReversePermutation(features=2))\n",
        "     transforms_l.append(NaiveLinear(features=2))\n",
        "\n",
        "transform_l = CompositeTransform(transforms_l)\n",
        "\n",
        "flow_l = Flow(transform_l, base_dist)\n",
        "optimizer_l = optim.Adam(flow_l.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMdwGIRNL54M",
        "outputId": "fa420f7a-c7b5-4197-d003-b363d1441e02"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nflows/utils/torchutils.py:73: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
            "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
            "Q, R = torch.qr(A, some)\n",
            "should be replaced with\n",
            "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1980.)\n",
            "  q, _ = torch.qr(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer_l.zero_grad()\n",
        "    loss_l = -flow_l.log_prob(inputs=x).mean()\n",
        "    loss_l.backward()\n",
        "    optimizer_l.step()"
      ],
      "metadata": {
        "id": "TlAaJDr9MOOu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def guassianNB_accuracy(flow):\n",
        "  max_accuracy = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = GaussianNB()\n",
        "    model_with_sampled_data = GaussianNB()\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy < accuracy:\n",
        "      max_accuracy = accuracy\n",
        "\n",
        "  print(max_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "GkQ4uLRYP9N2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_accuracy(flow):  \n",
        "  max_accuracy_lr = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = LogisticRegression(random_state = 0)\n",
        "    model_with_sampled_data = LogisticRegression(random_state = 0)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_lr < accuracy:\n",
        "      max_accuracy_lr = accuracy\n",
        "\n",
        "  print(max_accuracy_lr)"
      ],
      "metadata": {
        "id": "hSMSObf_RNEO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_accuracy(flow):\n",
        "  max_accuracy_knn = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = KNeighborsClassifier(n_neighbors=7)\n",
        "    model_with_sampled_data = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_knn < accuracy:\n",
        "      max_accuracy_knn = accuracy\n",
        "\n",
        "  print(max_accuracy_knn)"
      ],
      "metadata": {
        "id": "da3A30LWSym2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest_accuracy(flow):  \n",
        "  max_accuracy_rf = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = RandomForestClassifier(n_estimators = 100)\n",
        "    model_with_sampled_data = RandomForestClassifier(n_estimators = 100)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_rf < accuracy:\n",
        "      max_accuracy_rf = accuracy\n",
        "\n",
        "  print(max_accuracy_rf) #0.3"
      ],
      "metadata": {
        "id": "1svzjhfUTLz9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guassianNB_accuracy(flow)\n",
        "guassianNB_accuracy(flow_cl)\n",
        "guassianNB_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnDlCAQrMeEu",
        "outputId": "bd99b131-17a7-472a-f84e-17a09a516132"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8\n",
            "0.6466666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nflows/transforms/linear.py:183: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
            "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
            "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
            "X = torch.solve(B, A).solution\n",
            "should be replaced with\n",
            "X = torch.linalg.solve(A, B) (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:859.)\n",
            "  outputs, lu = torch.solve(outputs.t(), self._weight)  # Linear-system solver.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7733333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_accuracy(flow)\n",
        "logistic_regression_accuracy(flow_cl)\n",
        "logistic_regression_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqQ51OyLMkXg",
        "outputId": "1823e269-9ec8-44b5-ba82-9f4e7381ab1d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7666666666666667\n",
            "0.6533333333333333\n",
            "0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_accuracy(flow)\n",
        "knn_accuracy(flow_cl)\n",
        "knn_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZRO5ZOjMuUp",
        "outputId": "d33412fd-766c-4228-bbe8-7f911e0acc90"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8666666666666667\n",
            "0.5066666666666667\n",
            "0.7666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_accuracy(flow)\n",
        "random_forest_accuracy(flow_cl)\n",
        "random_forest_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsHz-qQ9Mzmr",
        "outputId": "8c4e9bab-dbb3-4cff-ba17-f9340c77fc0e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.76\n",
            "0.5533333333333333\n",
            "0.7533333333333333\n"
          ]
        }
      ]
    }
  ]
}