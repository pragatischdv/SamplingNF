{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sampling with Wheat Seed Dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfefKy3s6IorAmu6oyS9ao"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nflows"
      ],
      "metadata": {
        "id": "7uvCp3kaQ2YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D4JOI0r-QAuA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from sklearn.decomposition import PCA\n",
        " \n",
        "from nflows.flows.base import Flow\n",
        "from nflows.distributions.normal import StandardNormal\n",
        "from nflows.transforms.base import CompositeTransform\n",
        "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
        "from nflows.transforms.coupling import AffineCouplingTransform\n",
        "from nflows.transforms.linear import NaiveLinear\n",
        "from nflows.transforms.permutations import ReversePermutation\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/wheat-seed.csv\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DxrcgoWYDaf",
        "outputId": "c6555464-d55a-42bc-ae27-ca15adb2144d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Area  Perimeter  Compactness  Length  Width  Asymmetry_coefficient  \\\n",
            "0  15.26      14.84       0.8710   5.763  3.312                  2.221   \n",
            "1  14.88      14.57       0.8811   5.554  3.333                  1.018   \n",
            "2  14.29      14.09       0.9050   5.291  3.337                  2.699   \n",
            "3  13.84      13.94       0.8955   5.324  3.379                  2.259   \n",
            "4  16.14      14.99       0.9034   5.658  3.562                  1.355   \n",
            "\n",
            "   Groove_length  Class  \n",
            "0          5.220      1  \n",
            "1          4.956      1  \n",
            "2          4.825      1  \n",
            "3          4.805      1  \n",
            "4          5.175      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = data.drop(\"Class\", axis=1)\n",
        "output_data = np.array(data[\"Class\"])"
      ],
      "metadata": {
        "id": "jcALIwsLQchq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = pd.read_csv(\"/content/iris_flower.csv\")\n",
        "print(data2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjCakarLX4ve",
        "outputId": "5fce5827-ceaa-43ff-9f7f-8fb89df71e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width  type\n",
            "0           5.1          3.5           1.4          0.2   1.0\n",
            "1           4.9          3.0           1.4          0.2   1.0\n",
            "2           4.7          3.2           1.3          0.2   1.0\n",
            "3           4.6          3.1           1.5          0.2   1.0\n",
            "4           5.0          3.6           1.4          0.2   1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data3 = pd.read_csv(\"/content/swedish-insurance.csv\")\n",
        "print(data3.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9zY_ydLYDNx",
        "outputId": "fde201af-5360-4e49-fe2b-e68771132985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Claims  Payment\n",
            "0     108    392.5\n",
            "1      19     46.2\n",
            "2      13     15.7\n",
            "3     124    422.2\n",
            "4      40    119.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_CLASS_INT = 3\n",
        "MIN_CLASS_INT = 1\n",
        "N_SAMPLES = len(data)"
      ],
      "metadata": {
        "id": "45_o-vIePp47"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 1)\n",
        "input_data = pca.fit_transform(input_data)"
      ],
      "metadata": {
        "id": "XhVtasJ_RZWh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = []\n",
        "for i in range(len(output_data)):\n",
        "  final_data.append([input_data[i][0], output_data[i]])\n",
        "\n",
        "final_data = np.array(final_data)"
      ],
      "metadata": {
        "id": "zwGpxsluR9Oi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 7\n",
        "base_dist = StandardNormal(shape=[2])\n",
        "num_iter = 10000"
      ],
      "metadata": {
        "id": "0uLuvTwZJ34f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masked Autoregrssive Flow"
      ],
      "metadata": {
        "id": "rL2-aUeDKBzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = []\n",
        "for _ in range(num_layers):\n",
        "     transforms.append(MaskedAffineAutoregressiveTransform(features=2, \n",
        "                                                            hidden_features=4))\n",
        "\n",
        "transform = CompositeTransform(transforms)\n",
        "\n",
        "flow = Flow(transform, base_dist)\n",
        "optimizer = optim.Adam(flow.parameters())"
      ],
      "metadata": {
        "id": "Jmhisli0Q_Lb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer.zero_grad()\n",
        "    loss = -flow.log_prob(inputs=x).mean()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "ekMIO4xuRt3H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoregressive Flow with Coupling layer"
      ],
      "metadata": {
        "id": "kyKWGhhxLx5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = [1,1]\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channel, out_channels):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_channel, in_channel),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_channel, in_channel),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_channel, out_channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, inp, context=None):\n",
        "        return self.net(inp)\n",
        "\n",
        "def getNet(in_channel, out_channels):\n",
        "        return Net(in_channel, out_channels)\n",
        "transforms_cl = []\n",
        "for _ in range(num_layers):\n",
        "     transforms_cl.append(AffineCouplingTransform(mask, getNet))\n",
        "\n",
        "transform_cl = CompositeTransform(transforms_cl)\n",
        "\n",
        "flow_cl = Flow(transform_cl, base_dist)\n",
        "optimizer_cl = optim.Adam(flow_cl.parameters())"
      ],
      "metadata": {
        "id": "Vud6whJGJ0fj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer_cl.zero_grad()\n",
        "    loss_cl = -flow_cl.log_prob(inputs=x).mean()\n",
        "    loss_cl.backward()\n",
        "    optimizer_cl.step()"
      ],
      "metadata": {
        "id": "x8r7b9q8Kh2p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Flow"
      ],
      "metadata": {
        "id": "z-aUvPS9NXyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_l = []\n",
        "\n",
        "for _ in range(num_layers):\n",
        "     transforms_l.append(ReversePermutation(features=2))\n",
        "     transforms_l.append(NaiveLinear(features=2))\n",
        "\n",
        "transform_l = CompositeTransform(transforms_l)\n",
        "\n",
        "flow_l = Flow(transform_l, base_dist)\n",
        "optimizer_l = optim.Adam(flow_l.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMdwGIRNL54M",
        "outputId": "7c9344a0-37d8-4a47-8277-f6becf77e022"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nflows/utils/torchutils.py:73: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
            "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
            "Q, R = torch.qr(A, some)\n",
            "should be replaced with\n",
            "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1980.)\n",
            "  q, _ = torch.qr(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer_l.zero_grad()\n",
        "    loss_l = -flow_l.log_prob(inputs=x).mean()\n",
        "    loss_l.backward()\n",
        "    optimizer_l.step()"
      ],
      "metadata": {
        "id": "TlAaJDr9MOOu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def guassianNB_accuracy(flow):\n",
        "  max_accuracy = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = GaussianNB()\n",
        "    model_with_sampled_data = GaussianNB()\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy < accuracy:\n",
        "      max_accuracy = accuracy\n",
        "\n",
        "  print(max_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "GkQ4uLRYP9N2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_accuracy(flow):  \n",
        "  max_accuracy_lr = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = LogisticRegression(random_state = 0)\n",
        "    model_with_sampled_data = LogisticRegression(random_state = 0)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_lr < accuracy:\n",
        "      max_accuracy_lr = accuracy\n",
        "\n",
        "  print(max_accuracy_lr)"
      ],
      "metadata": {
        "id": "hSMSObf_RNEO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_accuracy(flow):\n",
        "  max_accuracy_knn = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = KNeighborsClassifier(n_neighbors=7)\n",
        "    model_with_sampled_data = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_knn < accuracy:\n",
        "      max_accuracy_knn = accuracy\n",
        "\n",
        "  print(max_accuracy_knn)"
      ],
      "metadata": {
        "id": "da3A30LWSym2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest_accuracy(flow):  \n",
        "  max_accuracy_rf = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = RandomForestClassifier(n_estimators = 100)\n",
        "    model_with_sampled_data = RandomForestClassifier(n_estimators = 100)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_rf < accuracy:\n",
        "      max_accuracy_rf = accuracy\n",
        "\n",
        "  print(max_accuracy_rf) #0.3"
      ],
      "metadata": {
        "id": "1svzjhfUTLz9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guassianNB_accuracy(flow)\n",
        "guassianNB_accuracy(flow_cl)\n",
        "guassianNB_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnDlCAQrMeEu",
        "outputId": "14f56fce-1306-4a02-c015-63a4fc1b70de"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7380952380952381\n",
            "0.6142857142857143\n",
            "0.32857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_accuracy(flow)\n",
        "logistic_regression_accuracy(flow_cl)\n",
        "logistic_regression_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqQ51OyLMkXg",
        "outputId": "d992bd85-a955-48cd-e636-bd76be375baa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5714285714285714\n",
            "0.6333333333333333\n",
            "0.319047619047619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_accuracy(flow)\n",
        "knn_accuracy(flow_cl)\n",
        "knn_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZRO5ZOjMuUp",
        "outputId": "c8f475bb-14ab-4131-ce05-6cb72034c9ea"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8380952380952381\n",
            "0.5238095238095238\n",
            "0.4238095238095238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_accuracy(flow)\n",
        "random_forest_accuracy(flow_cl)\n",
        "random_forest_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsHz-qQ9Mzmr",
        "outputId": "aa276856-62a6-4ba2-d690-1cf9be5e5738"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6571428571428571\n",
            "0.4666666666666667\n",
            "0.44285714285714284\n"
          ]
        }
      ]
    }
  ]
}