{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sampling with Wheat Seed Dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2X4sZa3rhG5ajJ2v3Xqlz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nflows"
      ],
      "metadata": {
        "id": "7uvCp3kaQ2YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4JOI0r-QAuA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from sklearn.decomposition import PCA\n",
        " \n",
        "from nflows.flows.base import Flow\n",
        "from nflows.distributions.normal import StandardNormal\n",
        "from nflows.transforms.base import CompositeTransform\n",
        "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
        "from nflows.transforms.coupling import AffineCouplingTransform\n",
        "from nflows.transforms.linear import NaiveLinear\n",
        "from nflows.transforms.permutations import ReversePermutation\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/wheat-seed.csv\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DxrcgoWYDaf",
        "outputId": "95740d90-efbe-406e-eea7-3076efcb22f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Area  Perimeter  Compactness  Length  Width  Asymmetry_coefficient  \\\n",
            "0  15.26      14.84       0.8710   5.763  3.312                  2.221   \n",
            "1  14.88      14.57       0.8811   5.554  3.333                  1.018   \n",
            "2  14.29      14.09       0.9050   5.291  3.337                  2.699   \n",
            "3  13.84      13.94       0.8955   5.324  3.379                  2.259   \n",
            "4  16.14      14.99       0.9034   5.658  3.562                  1.355   \n",
            "\n",
            "   Groove_length  Class  \n",
            "0          5.220      1  \n",
            "1          4.956      1  \n",
            "2          4.825      1  \n",
            "3          4.805      1  \n",
            "4          5.175      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = data.drop(\"Class\", axis=1)\n",
        "output_data = np.array(data[\"Class\"])"
      ],
      "metadata": {
        "id": "jcALIwsLQchq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_CLASS_INT = 3\n",
        "MIN_CLASS_INT = 1\n",
        "N_SAMPLES = len(data)"
      ],
      "metadata": {
        "id": "45_o-vIePp47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 1)\n",
        "input_data = pca.fit_transform(input_data)"
      ],
      "metadata": {
        "id": "XhVtasJ_RZWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = []\n",
        "for i in range(len(output_data)):\n",
        "  final_data.append([input_data[i][0], output_data[i]])\n",
        "\n",
        "final_data = np.array(final_data)"
      ],
      "metadata": {
        "id": "zwGpxsluR9Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 7\n",
        "base_dist = StandardNormal(shape=[2])\n",
        "num_iter = 10000"
      ],
      "metadata": {
        "id": "0uLuvTwZJ34f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masked Autoregrssive Flow"
      ],
      "metadata": {
        "id": "rL2-aUeDKBzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = []\n",
        "for _ in range(num_layers):\n",
        "     transforms.append(MaskedAffineAutoregressiveTransform(features=2, \n",
        "                                                            hidden_features=4))\n",
        "\n",
        "transform = CompositeTransform(transforms)\n",
        "\n",
        "flow = Flow(transform, base_dist)\n",
        "optimizer = optim.Adam(flow.parameters())"
      ],
      "metadata": {
        "id": "Jmhisli0Q_Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer.zero_grad()\n",
        "    loss = -flow.log_prob(inputs=x).mean()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "ekMIO4xuRt3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoregressive Flow with Coupling layer"
      ],
      "metadata": {
        "id": "kyKWGhhxLx5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask_1 = [0,1]\n",
        "mask_2 = [1,0]\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channel, out_channels):\n",
        "        super().__init__()\n",
        "        layers = [nn.Linear(in_channel, in_channel), \n",
        "                  nn.ReLU(), \n",
        "                  nn.Linear(in_channel, in_channel), \n",
        "                  nn.ReLU(), \n",
        "                  nn.Linear(in_channel, out_channels)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, inp, context=None):\n",
        "        return self.net(inp)\n",
        "\n",
        "def getNet(in_channel, out_channels):\n",
        "        return Net(in_channel, out_channels)\n",
        "transforms_cl = []\n",
        "for _ in range(2):\n",
        "     transforms_cl.append(AffineCouplingTransform(mask_1, getNet))\n",
        "     transforms_cl.append(AffineCouplingTransform(mask_2, getNet))\n",
        "\n",
        "transform_cl = CompositeTransform(transforms_cl)\n",
        "\n",
        "flow_cl = Flow(transform_cl, base_dist)\n",
        "optimizer_cl = optim.Adam(flow_cl.parameters())\n",
        "\n",
        "transform_cl = CompositeTransform(transforms_cl)\n",
        "\n",
        "flow_cl = Flow(transform_cl, base_dist)\n",
        "optimizer_cl = optim.Adam(flow_cl.parameters())"
      ],
      "metadata": {
        "id": "Vud6whJGJ0fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer_cl.zero_grad()\n",
        "    loss_cl = -flow_cl.log_prob(inputs=x).mean()\n",
        "    loss_cl.backward()\n",
        "    optimizer_cl.step()"
      ],
      "metadata": {
        "id": "x8r7b9q8Kh2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Flow"
      ],
      "metadata": {
        "id": "z-aUvPS9NXyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_l = []\n",
        "\n",
        "for _ in range(num_layers):\n",
        "     transforms_l.append(ReversePermutation(features=2))\n",
        "     transforms_l.append(NaiveLinear(features=2))\n",
        "\n",
        "transform_l = CompositeTransform(transforms_l)\n",
        "\n",
        "flow_l = Flow(transform_l, base_dist)\n",
        "optimizer_l = optim.Adam(flow_l.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMdwGIRNL54M",
        "outputId": "d0327e83-360c-4ff0-c230-aef32c5628d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nflows/utils/torchutils.py:73: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
            "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
            "Q, R = torch.qr(A, some)\n",
            "should be replaced with\n",
            "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1980.)\n",
            "  q, _ = torch.qr(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer_l.zero_grad()\n",
        "    loss_l = -flow_l.log_prob(inputs=x).mean()\n",
        "    loss_l.backward()\n",
        "    optimizer_l.step()"
      ],
      "metadata": {
        "id": "TlAaJDr9MOOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def guassianNB_accuracy(flow):\n",
        "  max_accuracy = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = GaussianNB()\n",
        "    model_with_sampled_data = GaussianNB()\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy < accuracy:\n",
        "      max_accuracy = accuracy\n",
        "\n",
        "  print(max_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "GkQ4uLRYP9N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_accuracy(flow):  \n",
        "  max_accuracy_lr = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = LogisticRegression(random_state = 0)\n",
        "    model_with_sampled_data = LogisticRegression(random_state = 0)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_lr < accuracy:\n",
        "      max_accuracy_lr = accuracy\n",
        "\n",
        "  print(max_accuracy_lr)"
      ],
      "metadata": {
        "id": "hSMSObf_RNEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_accuracy(flow):\n",
        "  max_accuracy_knn = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = KNeighborsClassifier(n_neighbors=7)\n",
        "    model_with_sampled_data = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_knn < accuracy:\n",
        "      max_accuracy_knn = accuracy\n",
        "\n",
        "  print(max_accuracy_knn)"
      ],
      "metadata": {
        "id": "da3A30LWSym2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest_accuracy(flow):  \n",
        "  max_accuracy_rf = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = RandomForestClassifier(n_estimators = 100)\n",
        "    model_with_sampled_data = RandomForestClassifier(n_estimators = 100)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_rf < accuracy:\n",
        "      max_accuracy_rf = accuracy\n",
        "\n",
        "  print(max_accuracy_rf) #0.3"
      ],
      "metadata": {
        "id": "1svzjhfUTLz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guassianNB_accuracy(flow)\n",
        "guassianNB_accuracy(flow_cl)\n",
        "guassianNB_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnDlCAQrMeEu",
        "outputId": "625e4ec8-0daa-4509-aed7-f9d6129020b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7952380952380952\n",
            "0.6666666666666666\n",
            "0.32857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_accuracy(flow)\n",
        "logistic_regression_accuracy(flow_cl)\n",
        "logistic_regression_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqQ51OyLMkXg",
        "outputId": "74ba0d05-deb6-4d6b-f2f5-ba5d09c13b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.45714285714285713\n",
            "0.6333333333333333\n",
            "0.319047619047619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_accuracy(flow)\n",
        "knn_accuracy(flow_cl)\n",
        "knn_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZRO5ZOjMuUp",
        "outputId": "cc1b0b82-2637-4c73-d082-4ac74fc3cb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8809523809523809\n",
            "0.6619047619047619\n",
            "0.40476190476190477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_accuracy(flow)\n",
        "random_forest_accuracy(flow_cl)\n",
        "random_forest_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsHz-qQ9Mzmr",
        "outputId": "ba16d416-3f97-42ae-dfa0-05851286e193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6904761904761905\n",
            "0.5619047619047619\n",
            "0.4714285714285714\n"
          ]
        }
      ]
    }
  ]
}