{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sampling with Wheat Seed Dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfkAaDuBOKztVWPw8ZYUG2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nflows"
      ],
      "metadata": {
        "id": "7uvCp3kaQ2YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "D4JOI0r-QAuA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from sklearn.decomposition import PCA\n",
        " \n",
        "from nflows.flows.base import Flow\n",
        "from nflows.distributions.normal import StandardNormal\n",
        "from nflows.transforms.base import CompositeTransform\n",
        "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
        "from nflows.transforms.coupling import AffineCouplingTransform\n",
        "from nflows.transforms.linear import NaiveLinear\n",
        "from nflows.transforms.permutations import ReversePermutation\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/wheat-seed.csv\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DxrcgoWYDaf",
        "outputId": "5c44e04d-69cc-4091-efda-3e6715892b45"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Area  Perimeter  Compactness  Length  Width  Asymmetry_coefficient  \\\n",
            "0  15.26      14.84       0.8710   5.763  3.312                  2.221   \n",
            "1  14.88      14.57       0.8811   5.554  3.333                  1.018   \n",
            "2  14.29      14.09       0.9050   5.291  3.337                  2.699   \n",
            "3  13.84      13.94       0.8955   5.324  3.379                  2.259   \n",
            "4  16.14      14.99       0.9034   5.658  3.562                  1.355   \n",
            "\n",
            "   Groove_length  Class  \n",
            "0          5.220      1  \n",
            "1          4.956      1  \n",
            "2          4.825      1  \n",
            "3          4.805      1  \n",
            "4          5.175      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = data.drop(\"Class\", axis=1)\n",
        "output_data = np.array(data[\"Class\"])"
      ],
      "metadata": {
        "id": "jcALIwsLQchq"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_CLASS_INT = 3\n",
        "MIN_CLASS_INT = 1\n",
        "N_SAMPLES = len(data)"
      ],
      "metadata": {
        "id": "45_o-vIePp47"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 1)\n",
        "input_data = pca.fit_transform(input_data)"
      ],
      "metadata": {
        "id": "XhVtasJ_RZWh"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = []\n",
        "for i in range(len(output_data)):\n",
        "  final_data.append([input_data[i][0], output_data[i]])\n",
        "\n",
        "final_data = np.array(final_data)"
      ],
      "metadata": {
        "id": "zwGpxsluR9Oi"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 7\n",
        "base_dist = StandardNormal(shape=[2])\n",
        "num_iter = 10000"
      ],
      "metadata": {
        "id": "0uLuvTwZJ34f"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masked Autoregrssive Flow"
      ],
      "metadata": {
        "id": "rL2-aUeDKBzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = []\n",
        "for _ in range(num_layers):\n",
        "     transforms.append(MaskedAffineAutoregressiveTransform(features=2, \n",
        "                                                            hidden_features=4))\n",
        "\n",
        "transform = CompositeTransform(transforms)\n",
        "\n",
        "flow = Flow(transform, base_dist)\n",
        "optimizer = optim.Adam(flow.parameters())"
      ],
      "metadata": {
        "id": "Jmhisli0Q_Lb"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer.zero_grad()\n",
        "    loss = -flow.log_prob(inputs=x).mean()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "ekMIO4xuRt3H"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoregressive Flow with Coupling layer"
      ],
      "metadata": {
        "id": "kyKWGhhxLx5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask_1 = [0,1]\n",
        "mask_2 = [1,0]\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channel, out_channels):\n",
        "        super().__init__()\n",
        "        layers = [nn.Linear(in_channel, in_channel), \n",
        "                  nn.ReLU(), \n",
        "                  nn.Linear(in_channel, in_channel), \n",
        "                  nn.ReLU(), \n",
        "                  nn.Linear(in_channel, out_channels)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, inp, context=None):\n",
        "        return self.net(inp)\n",
        "\n",
        "def getNet(in_channel, out_channels):\n",
        "        return Net(in_channel, out_channels)\n",
        "transforms_cl = []\n",
        "for _ in range(2):\n",
        "     transforms_cl.append(AffineCouplingTransform(mask_1, getNet))\n",
        "     transforms_cl.append(AffineCouplingTransform(mask_2, getNet))\n",
        "\n",
        "transform_cl = CompositeTransform(transforms_cl)\n",
        "\n",
        "flow_cl = Flow(transform_cl, base_dist)\n",
        "optimizer_cl = optim.Adam(flow_cl.parameters())\n",
        "\n",
        "transform_cl = CompositeTransform(transforms_cl)\n",
        "\n",
        "flow_cl = Flow(transform_cl, base_dist)\n",
        "optimizer_cl = optim.Adam(flow_cl.parameters())"
      ],
      "metadata": {
        "id": "Vud6whJGJ0fj"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer_cl.zero_grad()\n",
        "    loss_cl = -flow_cl.log_prob(inputs=x).mean()\n",
        "    loss_cl.backward()\n",
        "    optimizer_cl.step()"
      ],
      "metadata": {
        "id": "x8r7b9q8Kh2p"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Flow"
      ],
      "metadata": {
        "id": "z-aUvPS9NXyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_l = []\n",
        "\n",
        "for _ in range(num_layers):\n",
        "     transforms_l.append(ReversePermutation(features=2))\n",
        "     transforms_l.append(NaiveLinear(features=2))\n",
        "\n",
        "transform_l = CompositeTransform(transforms_l)\n",
        "\n",
        "flow_l = Flow(transform_l, base_dist)\n",
        "optimizer_l = optim.Adam(flow_l.parameters())"
      ],
      "metadata": {
        "id": "zMdwGIRNL54M"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_iter):\n",
        "    #x, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
        "    x = torch.tensor(final_data, dtype=torch.float32)\n",
        "    optimizer_l.zero_grad()\n",
        "    loss_l = -flow_l.log_prob(inputs=x).mean()\n",
        "    loss_l.backward()\n",
        "    optimizer_l.step()"
      ],
      "metadata": {
        "id": "TlAaJDr9MOOu"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def guassianNB_accuracy(flow):\n",
        "  max_accuracy = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = GaussianNB()\n",
        "    model_with_sampled_data = GaussianNB()\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy < accuracy:\n",
        "      max_accuracy = accuracy\n",
        "\n",
        "  print(max_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "GkQ4uLRYP9N2"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_accuracy(flow):  \n",
        "  max_accuracy_lr = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = LogisticRegression(random_state = 0)\n",
        "    model_with_sampled_data = LogisticRegression(random_state = 0)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_lr < accuracy:\n",
        "      max_accuracy_lr = accuracy\n",
        "\n",
        "  print(max_accuracy_lr)"
      ],
      "metadata": {
        "id": "hSMSObf_RNEO"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_accuracy(flow):\n",
        "  max_accuracy_knn = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = KNeighborsClassifier(n_neighbors=7)\n",
        "    model_with_sampled_data = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_knn < accuracy:\n",
        "      max_accuracy_knn = accuracy\n",
        "\n",
        "  print(max_accuracy_knn)"
      ],
      "metadata": {
        "id": "da3A30LWSym2"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest_accuracy(flow):  \n",
        "  max_accuracy_rf = 0\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_real_data = RandomForestClassifier(n_estimators = 100)\n",
        "    model_with_sampled_data = RandomForestClassifier(n_estimators = 100)\n",
        "\n",
        "    model_with_real_data.fit(final_data[:, 0].reshape(-1, 1), final_data[:, 1].reshape(-1, 1))\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_real = model_with_real_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "    pred_data_sampled = model_with_sampled_data.predict(final_data[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy_rf < accuracy:\n",
        "      max_accuracy_rf = accuracy\n",
        "\n",
        "  print(max_accuracy_rf) #0.3"
      ],
      "metadata": {
        "id": "1svzjhfUTLz9"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guassianNB_accuracy(flow)\n",
        "guassianNB_accuracy(flow_cl)\n",
        "guassianNB_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnDlCAQrMeEu",
        "outputId": "5443ae9e-0779-4235-aea3-8c807f4359a2"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6761904761904762\n",
            "0.49523809523809526\n",
            "0.38095238095238093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_accuracy(flow)\n",
        "logistic_regression_accuracy(flow_cl)\n",
        "logistic_regression_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqQ51OyLMkXg",
        "outputId": "f61129e1-bccb-42b9-9352-f13b81194cf6"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5476190476190477\n",
            "0.5857142857142857\n",
            "0.37142857142857144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_accuracy(flow)\n",
        "knn_accuracy(flow_cl)\n",
        "knn_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZRO5ZOjMuUp",
        "outputId": "031e8d06-2a4c-4971-f19e-26c98caf6df6"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.780952380952381\n",
            "0.5285714285714286\n",
            "0.44285714285714284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_accuracy(flow)\n",
        "random_forest_accuracy(flow_cl)\n",
        "random_forest_accuracy(flow_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsHz-qQ9Mzmr",
        "outputId": "64db9ea1-e12b-4fe9-f5e6-a11fca005fc7"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6857142857142857\n",
            "0.4857142857142857\n",
            "0.48095238095238096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_accuracy(flow, data_final):\n",
        "  test_set = data_final[:50]\n",
        "  train_set = data_final[50:]\n",
        "  model_with_real_data = GaussianNB()\n",
        "  model_with_real_data.fit(train_set[:, 0].reshape(-1, 1), train_set[:, 1].reshape(-1, 1))\n",
        "  pred_data_real_2 = model_with_real_data.predict(data_final[:, 0].reshape(-1, 1))\n",
        "  pred_data_real = model_with_real_data.predict(test_set[:, 0].reshape(-1, 1))\n",
        "  original_accuracy = accuracy_score(pred_data_real,test_set[:, 1].reshape(-1, 1))\n",
        "\n",
        "  max_accuracy = 0\n",
        "  final_sampled_pred_data = []\n",
        "  final_sample = []\n",
        "  for i in range(100):\n",
        "    samples = flow.sample(N_SAMPLES)\n",
        "    samples = samples.detach().numpy()\n",
        "\n",
        "    y_sample = samples[:, 1]\n",
        "    for i in range(N_SAMPLES):\n",
        "      y_sample[i] = math.floor(y_sample[i])\n",
        "      if y_sample[i] < MIN_CLASS_INT:\n",
        "        y_sample[i] = MIN_CLASS_INT\n",
        "      elif y_sample[i] > MAX_CLASS_INT:\n",
        "        y_sample[i] = MAX_CLASS_INT\n",
        "\n",
        "    model_with_sampled_data = GaussianNB()\n",
        "\n",
        "    model_with_sampled_data.fit(samples[:, 0].reshape(-1, 1), samples[:, 1].reshape(-1, 1))\n",
        "\n",
        "    pred_data_sampled = model_with_sampled_data.predict(data_final[:, 0].reshape(-1, 1))\n",
        "\n",
        "    accuracy = accuracy_score(pred_data_real_2,pred_data_sampled)\n",
        "\n",
        "    if max_accuracy < accuracy:\n",
        "      max_accuracy = accuracy\n",
        "      final_sampled_pred_data = pred_data_sampled\n",
        "      final_sample = samples\n",
        "\n",
        "\n",
        "  new_data = []  \n",
        "  for i in range(N_SAMPLES):\n",
        "    if final_sampled_pred_data[i] == pred_data_real_2[i]:\n",
        "      new_data.append(final_sample[i])\n",
        "  new_data = np.array(new_data)\n",
        "  new_data = new_data.tolist()\n",
        "  data_final = data_final.tolist()\n",
        "\n",
        "  new_data.extend(data_final)\n",
        "  new_data = np.array(new_data)\n",
        "  data_final = np.array(data_final)\n",
        "  model_with_new_data = GaussianNB()\n",
        "  model_with_new_data.fit(new_data[:, 0].reshape(-1, 1), new_data[:, 1].reshape(-1, 1))\n",
        "  pred_data_new = model_with_new_data.predict(test_set[:, 0].reshape(-1, 1))\n",
        "  new_accuracy = accuracy_score(pred_data_new,test_set[:, 1].reshape(-1, 1))\n",
        "\n",
        "  return original_accuracy, new_accuracy\n",
        "\n",
        "def data_accuracy_2(flow, data_f):\n",
        "  min_ = 9999\n",
        "  orig = 0\n",
        "  new = 0\n",
        "  for i in range(50):\n",
        "    o, n = data_accuracy(flow, data_f)\n",
        "    if min_ > (o-n):\n",
        "      min_ = o-n\n",
        "      orig = o\n",
        "      new = n\n",
        "  print(orig)\n",
        "  print(n)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "np.random.shuffle(final_data)"
      ],
      "metadata": {
        "id": "-inXkjyXToD2"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_accuracy_2(flow, final_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBxqzs1ATsIi",
        "outputId": "a0c460cc-54f9-48ca-d287-58a9cbaa970e"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.84\n",
            "0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_accuracy_2(flow_cl, final_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQM315HuTz1c",
        "outputId": "af6e8180-e3b1-48cc-9702-841b0fec0681"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.84\n",
            "0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_accuracy_2(flow_l, final_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIFWLB_XT3vs",
        "outputId": "04dd3872-fa5d-4561-d03a-fe98c4766fb5"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.84\n",
            "0.84\n"
          ]
        }
      ]
    }
  ]
}